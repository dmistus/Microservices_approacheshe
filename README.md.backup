# «Микросервисы: подходы»

### Задача 1: Обеспечить разработку

*Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка.* 
*Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.*



#### Для вышеуказанных требований подходит GitLab в связке с HashiCorp Vault:

* облачная система - GitLab возможно развернуть в облаке, например Yandex или Google;
система контроля версий Git - GitLab основан на Git;

* репозиторий на каждый сервис - GitLab можно создавать неограниченное количество репозиториев;

* запуск сборки по событию из системы контроля версий - Запуск пайплайна возможен по событию в VCS (commit, tag creation, итд.);

* запуск сборки по кнопке с указанием параметров - Возможен ручной запуск пайплайнов;
возможность привязать настройки к каждой сборке - В GitLab есть возможность привязывать переменные к пайплайну;

* возможность создания шаблонов для различных конфигураций сборок - GitLab поддерживает кастомизированные шаблоны;

* возможность безопасного хранения секретных данных (пароли, ключи доступа) - GitLab поддерживает интеграцию с HashiCorp Vault;

* несколько конфигураций для сборки из одного репозитория - GitLab позволяет создавать различные пайплайны для одного репозитория;

* кастомные шаги при сборке - В GitLab пайплайне можно прописывать кастомные stages;
собственные докер-образы для сборки проектов - GitLab позволяет использовать любые образы при конфигурации docker-раннера;

* возможность развернуть агентов сборки на собственных серверах - Возможна конфигурация раннера на любом сервере (облачном и физическом);

* возможность параллельного запуска нескольких сборок - Количество параллельных запусков пайплайнов не ограничено;

* возможность параллельного запуска тестов - Количество параллельных запусков пайплайнов с тестами не ограничего.

Вместо GitLab можно использовать свои сервера Git и Jenkins


### Задача 2: Логи


### Для требуемых условий возможно использовать Fluentd + ELK-стэк.

* Fluentd может собирать данные из различных источников, обрабатывать их и направлять в различные хранилища данных.

* Logstash будет принимать логи от агентов Fluentd и преобразовывать логи в единому формату.

* Elasticsearch будет хранить логи, для обеспечения отказоустойчивости возможно создать Elasticsearch-кластер.

* Kibana будет удобно отображать логи в web-интерфейсе. Используя Kibana можно создавать различные Dashboard для удобного просмотра логов, подсчета каких-либо событий, использовать различные временные метки.

В качестве альтернативы Logstash можно использовать Apache Kafka. Он также получает данные их различных источников, обеспечивает высокую скорость обработки данных, поддерживает кластеризацию. Можно разделить получаемые данные по разным топикам, для топиков можно настроить разное время хранения данных и их объем. Для передачи данных из Kafka в Elasticsearch используется специальный коннектор "Kafka Connect Elasticsearch Sink Connector".

### Задача 3: Мониторинг

#### *Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.*

*Решение должно соответствовать следующим требованиям:*

сбор метрик со всех хостов, обслуживающих систему;

сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;

сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;

сбор метрик, специфичных для каждого сервиса;

пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;

пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

### *Обоснуйте свой выбор.*


Для требуемых условий возможно использовать связку Prometheus + Grafana.

Prometheus - это система мониторинга и оповещения с открытым исходным кодом. Позволяет собирать метрики с различных источников, может выполнять агрегацию данных, быстро получать эти данные используя запросы к базе, визуализировать данные и оповещать о проблемах в сервисах на основе полученных метрик. Prometheus получает данные от различных агентов, например, может получить метрики загрузки CPU от node_exporter или метрики Docker контейнеров от Cadvisor. Также может работать совместно с Telegraf, который в свою очередь способен получать метрики из очень большого множества источников.

Grafana - web-интерфейс для визуализации данных. Может строить графики, Dashboard, визуализирует данные из большого числа систем мониторинга и большого числа разных метрик. К нему можно подключить большое количество источников, таких как Telegraf, Prometheus, InfluxDB и т.д.